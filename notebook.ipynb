{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carla speed limit assist with corrective actions and traffic light detection and warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library\n",
    "- **cv2 (OpenCV):** computer vision library for image processing. Used for handling and processing video frames or images.\n",
    "- **paho.mqtt.client:** client library for the MQTT protocol, this library permit to publish MQTT topics, likely for exchanging data between the CARLA simulator and other systems.\n",
    "- **ultralytics (YOLO):** provides Python interface for the YOLO (You Only Look Once) object detection framework. It provide object detection tasks, such as identify traffic light, speedLimit.\n",
    "- **pygame:** library for creating games and multimedia applications, it allows to take input events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import paho.mqtt.client as mqtt\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "import carla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broker MQTT configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BROKER = \"localhost\"\n",
    "PORT = 1883    \n",
    "\n",
    "clientMQTT = mqtt.Client()\n",
    "clientMQTT.connect(BROKER, PORT, 60)\n",
    "def sendEventToBroker(topic, message):\n",
    "    try:\n",
    "        clientMQTT.publish(topic, message)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "client.load_world('Town01')\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful functions used in this notebook\n",
    "- **spawn_vehicle:** Adds a vehicle to the simulation.\n",
    "  - Picks a vehicle type from the blueprint library (pattern).\n",
    "  - Selects a spawn point on the map (spawn_index).\n",
    "  - Places the vehicle at that location.\n",
    "- **spawn_camera** Adds a camera to the simulation.\n",
    "  - Sets the camera size, field of view (foV), and update speed.\n",
    "  - Places the camera at a specific position and angle.\n",
    "  - Attaches the camera to a vehicle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 640\n",
    "currect_map = False\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.*'):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "if world.get_map().name == \"Town02\" or world.get_map().name == \"Town01\":\n",
    "    currect_map = True\n",
    "\n",
    "def spawn_camera(attach_to=None, sensor_tick=0, transform=carla.Transform(carla.Location(x=0.7, z=1.8), carla.Rotation(pitch=5, yaw=35)), width=IMAGE_SIZE, height=IMAGE_SIZE, foV=50, exposure_mode='auto', expousure_compensation=0):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera_bp.set_attribute('fov', str(foV))\n",
    "    camera_bp.set_attribute('sensor_tick', str(sensor_tick))\n",
    "    camera_bp.set_attribute('bloom_intensity', \"0\")\n",
    "    camera_bp.set_attribute('exposure_mode', exposure_mode)\n",
    "    camera_bp.set_attribute('exposure_compensation', str(expousure_compensation))  # Riduce la luminosità\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training YOLOv8 Models for Object Detection\n",
    "\n",
    "### Overview\n",
    "We have trained the **YOLOv8** model multiple times to detect specific objects with two categories:\n",
    "\n",
    "1. **Speed Limits**:\n",
    "    - **First Training**: Using images of the speed limit signs without any background.\n",
    "    - **Second Training**: Using images of speed limit signs in real-world environments, with significant background clutter for object detection.\n",
    "\n",
    "2. **Traffic Lights**:\n",
    "    - **First Training**: Using images of the traffic lights without any background.\n",
    "    - **Second Training**: Using images of traffic lights in real-world environments, with significant background clutter for object detection.\n",
    "\n",
    "At the end, we will have **two YOLOv8 models**:\n",
    "- One dedicated to **speed limits**.\n",
    "- One dedicated to **traffic lights**.\n",
    "\n",
    "### Dataset\n",
    "The datasets used for training were sourced from the following site:  \n",
    "[Roboflow Universe](https://universe.roboflow.com/)\n",
    "\n",
    "### Base Code for Downloading and Training the Model\n",
    "Below is the base code to download the dataset and train the YOLOv8 model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install roboflow\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"...\")\n",
    "# project = rf.workspace(\"wawan-pradana\").project(\"cinta_v2\")\n",
    "# dataset = project.version(1).download(\"yolov8\")\n",
    "# model = YOLO('yolov8n.pt')\n",
    "# results = model.train(data=\"data.yaml\", epochs=80, imgsz=416, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model Results\n",
    "<img src=\"runsSpeed/detect/train/confusion_matrix.png\" alt=\"Descrizione dell'immagine\" width=\"700\">\n",
    "<img src=\"runsTrafficLight/detect/train3/confusion_matrix.png\" alt=\"Descrizione dell'immagine\" width=\"700\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runsSpeed/detect/train/weights/best.pt\")\n",
    "#modelTrafficLight = YOLO(\"runsUlt/detect/train7/weights/best.pt\")\n",
    "modelTrafficLight = YOLO(\"runsFinLight/detect/train/weights/best.pt\")\n",
    "modelTrafficLightOver = YOLO(\"runsFinLight/detect/train/weights/best.pt\")\n",
    "#modelTrafficLightOver = YOLO(\"runsTrafficLight/detect/train3/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set weather conditions\n",
    "- Set the worst weather condition or the best weather condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = world.get_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.sun_azimuth_angle = 0\n",
    "weather.sun_altitude_angle = -90\n",
    "weather.cloudiness = 100\n",
    "weather.precipitation = 100\n",
    "weather.precipitation_deposits = 100\n",
    "weather.wind_intensity = 100\n",
    "weather.fog_density = 100\n",
    "weather.fog_distance = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.sun_azimuth_angle = 0 \n",
    "weather.sun_altitude_angle = 90\n",
    "weather.cloudiness = 20\n",
    "weather.precipitation = 0\n",
    "weather.precipitation_deposits = 0\n",
    "weather.wind_intensity = 0\n",
    "weather.fog_density = 30\n",
    "weather.fog_distance = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.set_weather(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "- **colorSpeedLimit**: Change the letters color in the view.\n",
    "- **calcColor**: Change the letters color of the traffic light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorSpeedLimit(current_speed, speed_limit):\n",
    "    if speed_limit == None or int(current_speed) <= int(speed_limit):\n",
    "        return (0, 255, 0) \n",
    "    else:\n",
    "        return (0, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcColor():\n",
    "    if traffic_light == \"red\":\n",
    "        return (0, 0, 255)\n",
    "    elif traffic_light == \"yellow\":\n",
    "        return (0, 255, 255)\n",
    "    elif traffic_light == \"green\":\n",
    "        return (0, 255, 0)\n",
    "    else:\n",
    "        return (255, 255, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera_callback:\n",
    "\n",
    "This function processes an image captured by a camera, analyzes it using a machine learning model, and identifies the most likely speed limit sign if found with sufficient confidence:\n",
    "\n",
    "1. **Global Variables:**\n",
    "   - `last_analysis_time`: Tracks the time of the last analysis to ensure periodic processing.\n",
    "   - `last_speed_limit`: Stores the most recently detected speed limit.\n",
    "\n",
    "2. **Image Data Conversion:**\n",
    "   - The raw image data is read into a NumPy array using `np.frombuffer`, which converts the data into a byte array.\n",
    "   - The image is reshaped into its original dimensions, including the alpha channel (RGBA format).\n",
    "   - The alpha channel is removed to work with the RGB image, creating `image_bgr`.\n",
    "\n",
    "3. **Periodic Analysis:**\n",
    "   - Checks if enough time `analysis_interval` has passed since the last analysis using the current timestamp.\n",
    "   - If the time interval condition is met, updates `last_analysis_time`.\n",
    "\n",
    "4. **Model Prediction:**\n",
    "   - The resized image is passed to a machine learning model (`model`) for analysis.\n",
    "   - Extracts the detected class IDs (`class_ids`) and their confidence scores (`confidences`) from the model's results.\n",
    "\n",
    "5. **Identify Speed Limit:**\n",
    "   - Iterates through the detected objects, finding the class ID with the highest confidence score.\n",
    "   - If the confidence score exceeds a threshold (`0.87`), determines the corresponding class name.\n",
    "\n",
    "6. **Extract Speed Limit and Notify:**\n",
    "   - Attempts to extract the speed limit value from the class name.\n",
    "   - Updates `last_speed_limit` with the detected value.\n",
    "   - Sends an event with the detected speed limit to an external broker using `sendEventToBroker`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_callback(image):\n",
    "    global last_speed_limit\n",
    "\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    image_bgr = image_np[:, :, :3]  \n",
    "\n",
    "    results = model(image_bgr, verbose=False)\n",
    "    limit_id = None\n",
    "    confidence_max = 0\n",
    "    class_ids = results[0].boxes.cls.numpy()\n",
    "    confidences = results[0].boxes.conf.numpy()\n",
    "    \n",
    "    for class_id, confidence in zip(class_ids, confidences):\n",
    "        if confidence > confidence_max:\n",
    "            limit_id = class_id\n",
    "            confidence_max = confidence\n",
    "\n",
    "    if confidence_max > 0.87:\n",
    "        class_name = class_names[int(limit_id)]\n",
    "        try:\n",
    "            last_speed_limit = class_name.split(\" \")[2]\n",
    "            sendEventToBroker(\"speedLimit\", \"Detected \" + last_speed_limit)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera_view_callback:\n",
    "\n",
    "This function processes an image captured by a camera, calculates the vehicle's speed, and updates the global variables used for video output and speed monitoring:\n",
    "\n",
    "1. **Global Variables:**\n",
    "   - `video_output`: A global variable used to store the processed image data for visualization or further use.\n",
    "   - `speed_car`: A global variable used to store the vehicle's current speed.\n",
    "\n",
    "2. **Speed Calculation:**\n",
    "   - Retrieves the vehicle's velocity using `vehicle.get_velocity()`, which provides the velocity components along the X, Y, and Z axes.\n",
    "   - Computes the magnitude of the velocity vector using the formula for Euclidean norm.\n",
    "   - Converts the speed from meters per second (m/s) to kilometers per hour (km/h) by multiplying by 3.6.\n",
    "   - Updates the global variable `speed_car` with the calculated speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_view_callback(image):\n",
    "    global video_output, speed_car\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    velocity_car = vehicle.get_velocity()\n",
    "    speed_car = 3.6 * (velocity_car.x**2 + velocity_car.y**2 + velocity_car.z**2)**0.5\n",
    "    video_output = image_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera_traffic_callback:\n",
    "This function processes an image from a camera to detect the current state of a traffic light, applying enhancements to the image and analyzing it with a machine learning model. It updates global variables and notifies changes:\n",
    "\n",
    "1. **Global Variables:**\n",
    "   - `last_analysis_time_trafficLight`: Tracks the time of the last traffic light analysis to ensure periodic processing.\n",
    "   - `traffic_light`: Stores the detected traffic light state (`\"red\"`, `\"yellow\"`, `\"green\"`, or `\"Not detected\"`).\n",
    "\n",
    "2. **Image Data Conversion:**\n",
    "   - Converts the raw image data from the camera into a NumPy array using `np.frombuffer`.\n",
    "   - Reshapes the array into an image matrix of size `IMAGE_SIZE x IMAGE_SIZE` with 4 channels (BGRA format).\n",
    "   - Creates a copy of the RGB portion (`image_bgr`) for further processing.\n",
    "\n",
    "3. **Image Preprocessing:**\n",
    "   - **Color Enhancement:** Increases the red channel values to accentuate red tones, reduces blue and green values slightly to suppress their dominance, and creates an enhanced image for better detection.\n",
    "   - **Clipping Values:** Ensures pixel values remain in the valid range (0–255).\n",
    "\n",
    "1. **Periodic Analysis:**\n",
    "   - Checks if the interval since the last analysis exceeds a defined threshold (`analysis_interval_trafficLight`).\n",
    "   - Updates `last_analysis_time_trafficLight` when a new analysis is performed.\n",
    "\n",
    "2. **Traffic Light Detection:**\n",
    "   - Passes the processed image (`resized_image`) to a traffic light detection model (`modelTrafficLight`).\n",
    "   - Retrieves the detected class IDs (`class_ids`) and their confidence scores (`confidences`).\n",
    "   - Handles cases where no traffic lights are detected by setting `traffic_light` to `\"Not detected\"`.\n",
    "\n",
    "3. **Identify Most Likely Traffic Light:**\n",
    "   - Iterates through detected objects, identifying the class ID with the highest confidence score.\n",
    "   - It assigns the detected class name as the current traffic light state.\n",
    "   - Applies confidence thresholds:\n",
    "     - High confidence (`>0.63`) for red light.\n",
    "     - Lower confidence (`>0.47`) for other colors.\n",
    "\n",
    "4. **Update and Notify:** Sends an event to an external broker using `sendEventToBroker` with the detected traffic light state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_traffic_callback(image):\n",
    "    global traffic_light#, video_output2\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    image_bgr = image_np[:, :, :3].copy()\n",
    "    resized_image = image_bgr.copy()\n",
    "    #video_output2 = image_bgr\n",
    "\n",
    "    results = modelTrafficLight(resized_image, verbose=False)\n",
    "    trafficLight_id = None\n",
    "    confidence_max = 0\n",
    "    class_ids = results[0].boxes.cls.numpy()\n",
    "    confidences = results[0].boxes.conf.numpy()\n",
    "\n",
    "    if class_ids.size == 0:\n",
    "        traffic_light = \"Not detected\"\n",
    "    else:\n",
    "        for class_id, confidence in zip(class_ids, confidences):\n",
    "            if confidence > confidence_max:\n",
    "                trafficLight_id = class_id\n",
    "                confidence_max = confidence\n",
    "\n",
    "        if traffic_light != None and class_names_trafficLight[int(trafficLight_id)] == \"yellow\" and traffic_light == \"red\":\n",
    "            class_name = \"red\"\n",
    "        else:\n",
    "            class_name = class_names_trafficLight[int(trafficLight_id)]\n",
    "        if confidence_max > 0.55 and class_name==\"red\" or confidence_max > 0.50 and class_name==\"green\" or confidence_max > 0.50 and class_name==\"yellow\":\n",
    "            # print(confidence_max)\n",
    "            if traffic_light != class_name:\n",
    "                traffic_light = class_name\n",
    "                sendEventToBroker(\"TrafficLight\", \"Detected trafficlight \" + class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera_traffic_red_callback:\n",
    "\n",
    "This function operates similarly to `camera_traffic_callback(image)` but focuses specifically on detecting and reacting to **red traffic lights**, modifying a global flag (`red_over`) based on the detection results:\n",
    "\n",
    "1. **Global Variables:**\n",
    "   - `last_analysis_time_trafficLight_red`: Tracks the time of the last analysis for red traffic lights to ensure periodic updates.\n",
    "   - `red_over`: A flag indicating whether a red light condition has been detected and action of stopping should be enforced.\n",
    "\n",
    "2. **Traffic Light Detection:**\n",
    "   - Passes the processed image to the `modelTrafficLight`, which detects traffic light states and outputs class IDs (`class_ids`) and their confidence scores (`confidences`).\n",
    "   - Handles cases where no traffic lights are detected by resetting `red_over` to `False`.\n",
    "\n",
    "3. **Red Light Detection Logic:**\n",
    "   - Iterates through detected objects, identifying the class ID with the highest confidence score.\n",
    "   - If the detected class is `\"red\"` and the confidence score exceeds `0.65`: Sets `red_over` to `True` **unless the vehicle is in reverse (`gear != \"Reverse\"`)** or another condition prevents it.\n",
    "   - If the detected class is `\"green\"` or `\"yellow\"` and the confidence score exceeds `0.43`: Resets `red_over` to `False`, allowing movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_traffic_red_callback(image):\n",
    "    global red_over\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    image_bgr = image_np[:, :, :3].copy()\n",
    "    resized_image = image_bgr.copy()\n",
    "\n",
    "    results = modelTrafficLightOver(resized_image, verbose=False)\n",
    "\n",
    "    trafficLight_id = None\n",
    "    confidence_max = 0\n",
    "\n",
    "    class_ids = results[0].boxes.cls.numpy()\n",
    "    confidences = results[0].boxes.conf.numpy()\n",
    "\n",
    "    if class_ids.size != 0:\n",
    "        for class_id, confidence in zip(class_ids, confidences):\n",
    "            if confidence > confidence_max:\n",
    "                trafficLight_id = class_id\n",
    "                confidence_max = confidence\n",
    "\n",
    "        class_name = class_names_trafficLight[int(trafficLight_id)]\n",
    "        if class_name==\"red\" and confidence_max > 0.50:\n",
    "            if(gear != \"Reverse\" and not red_over):\n",
    "                red_over = True\n",
    "        elif (class_name==\"green\" or class_name==\"yellow\") and confidence_max > 0.43:\n",
    "            red_over = False\n",
    "    else:\n",
    "        red_over = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "This code use camera feeds, traffic light detection, and manual/automatic controls:\n",
    "\n",
    "### 1. **Setup and Initialization**\n",
    "   - **Pygame Window:** Creates a minimal interface using Pygame, used for event handling keyboard inputs.\n",
    "   - **Global Variables:**\n",
    "     - Includes control parameters for throttle, brake, and steering.\n",
    "     - Flags for managing speed control, red light detection, and traffic light states.\n",
    "     - Constants for proportional control of throttle and brake adjustments based on speed error.\n",
    "   - **Timers and Analysis Intervals:** Tracks the timing of camera analyses for speed, traffic lights, and red light violations.\n",
    "   - **Camera Feeds:** Initializes multiple cameras:\n",
    "     - Main RGB camera for capturing the environment.\n",
    "     - Additional cameras for detecting traffic lights, speed limits and specific red light conditions.\n",
    "   - **Vehicle Spawning:** Spawns a simulated vehicle in CARLA and attaches the cameras to it.\n",
    "\n",
    "### 2. **Real-Time Display and Feedback**\n",
    "   - Displays:\n",
    "     - Current speed and detected speed limits.\n",
    "     - Traffic light state (e.g., `\"red\"`, `\"green\"`).\n",
    "     - A warning if the vehicle violates a red light.\n",
    "\n",
    "### 3. **Camera-Based Analysis**\n",
    "   - Each camera captures frames periodically, which are processed for specific tasks:\n",
    "     - **Speed Limit Detection:** Uses object detection to identify speed limit signs.\n",
    "     - **Traffic Light State Detection:** Identifies traffic light states and updates global flags.\n",
    "     - **Red Light Violations:** Specifically monitors red lights and determines if the vehicle violates them.\n",
    "\n",
    "### 4. **Event Handling and Controls**\n",
    "   - **Keyboard Controls:**\n",
    "     - Toggle speed control (`E`), red light detection (`O`), and autopilot (enable `C`, disable `V`).\n",
    "     - Manual acceleration: (`W`), braking (`S`), steering (`A`/`D`), and gear selection (`R`/`F`).\n",
    "   - **Speed Control Logic:**\n",
    "     - Automatically adjusts throttle and brake based on the speed limit.\n",
    "     - Includes a \"dead zone\" around the speed limit to prevent constant adjustments.\n",
    "   - **Red Light Response:**\n",
    "     - Automatically engages brakes when a red light is detected and speed under 40 km/h.\n",
    "\n",
    "### 5. **Vehicle State Updates**\n",
    "   - Continuously updates the vehicle's control inputs (`throttle`, `brake`, `steer`) based on manual or automatic inputs.\n",
    "   - Ensures smooth transitions, such as gradual steering return to center when no input is applied.\n",
    "\n",
    "### 6. **Cleanup**\n",
    "   - Gracefully terminates the simulation, destroying the cameras, vehicle, and display, and disconnecting any external connections (e.g., MQTT broker).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a small Pygame display for handling events\n",
    "display = pygame.display.set_mode((50, 50))\n",
    "pygame.display.set_caption(\"Manual Control CARLA\")\n",
    "\n",
    "# Define control variables and increments\n",
    "steer_increment = 0.02  # Increment for steering adjustments\n",
    "throttle_increment = 0.1  # Increment for throttle adjustments\n",
    "steer = 0.0  # Current steering value\n",
    "throttle = 0.0  # Current throttle value\n",
    "brake = 0.0  # Current brake value\n",
    "global gear  # Define a global gear variable\n",
    "gear = \"Drive\"  # Initial gear state\n",
    "speed_control_activate = False  # Flag for speed control activation\n",
    "red_over_activate = False  # Flag for red light detection activation\n",
    "red_over = False  # Red light violation flag\n",
    "\n",
    "# Constants for proportional controller\n",
    "KP_THROTTLE = 0.15  # Proportional gain for acceleration\n",
    "KP_BRAKE = 0.02  # Proportional gain for braking\n",
    "DEAD_ZONE = 3.0  # Dead zone around the speed limit\n",
    "MIN_THROTTLE = 0.2  # Minimum throttle value\n",
    "MIN_BRAKE = 0.1  # Minimum brake value\n",
    "\n",
    "# Initialize the output video frame\n",
    "video_output = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n",
    "\n",
    "# Variables for speed and traffic light tracking\n",
    "last_speed_limit = None  # Last detected speed limit\n",
    "speed_car = 0  # Current vehicle speed\n",
    "traffic_light = \"Not detected\"  # Current traffic light state\n",
    "\n",
    "# Load class names for object detection models\n",
    "class_names = model.names  # Object detection model names\n",
    "class_names_trafficLight = modelTrafficLight.names  # Traffic light model names\n",
    "\n",
    "# Spawn the simulated vehicle\n",
    "vehicle = spawn_vehicle()\n",
    "\n",
    "\n",
    "# Attach and configure cameras for various purposes\n",
    "camera = spawn_camera(attach_to=vehicle, sensor_tick=0.2)  # Main camera\n",
    "camera.listen(lambda image: camera_callback(image))  # Listen for incoming frames\n",
    "\n",
    "camera_view = spawn_camera(\n",
    "    attach_to=vehicle, \n",
    "    sensor_tick=0.0,\n",
    "    transform=carla.Transform(carla.Location(x=1, z=1.5), carla.Rotation(pitch=0, yaw=0)), \n",
    "    width=IMAGE_SIZE, \n",
    "    height=IMAGE_SIZE, \n",
    "    foV=70\n",
    ")  # Driver's perspective camera\n",
    "camera_view.listen(lambda image: camera_view_callback(image))\n",
    "\n",
    "# Additional cameras for traffic light and red light detection\n",
    "if currect_map:\n",
    "    camera_trafficLight = spawn_camera(\n",
    "        attach_to=vehicle, \n",
    "        sensor_tick=0.35,\n",
    "        transform=carla.Transform(carla.Location(x=0.3, y=1, z=1.2), carla.Rotation(pitch=5, yaw=0)), \n",
    "        width=IMAGE_SIZE, \n",
    "        height=IMAGE_SIZE, \n",
    "        foV=40,\n",
    "    )\n",
    "    camera_trafficLight.listen(lambda image: camera_traffic_callback(image))\n",
    "    \n",
    "    camera_trafficLight_red_detector = spawn_camera(\n",
    "        attach_to=vehicle,\n",
    "        sensor_tick=0.35,\n",
    "        transform=carla.Transform(carla.Location(x=-1.8, y=0, z=2), carla.Rotation(pitch=0, yaw=0)), \n",
    "        width=IMAGE_SIZE, \n",
    "        height=IMAGE_SIZE, \n",
    "        foV=110\n",
    "    )\n",
    "    camera_trafficLight_red_detector.listen(lambda image: camera_traffic_red_callback(image))\n",
    "\n",
    "# Create an OpenCV window for displaying results\n",
    "cv2.namedWindow('RGB Camera', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "#cv2.namedWindow('RGB Camera2', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "try:\n",
    "    clock = pygame.time.Clock()  # Pygame clock for controlling loop rate\n",
    "    event_timer = 0  # Timer for event processing\n",
    "    EVENT_RATE = 100  # Event handling interval in milliseconds\n",
    "\n",
    "    while True:\n",
    "        # Add text overlays to the output frame\n",
    "        temp_frame = video_output.copy()\n",
    "        cv2.putText(\n",
    "            temp_frame,\n",
    "            f\"Last Speed Limit: {last_speed_limit}\",\n",
    "            (10, 20),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            temp_frame,\n",
    "            f\"Current speed: {speed_car:.0f}\",\n",
    "            (10, 45),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            colorSpeedLimit(speed_car, last_speed_limit),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        # Display traffic light information and warnings\n",
    "        if currect_map:\n",
    "            if red_over:\n",
    "                val = \"You ran a red light\"\n",
    "                sendEventToBroker(\"TrafficLightViolation\", \"Red light violation\")\n",
    "            else:\n",
    "                val = \"\"\n",
    "            cv2.putText(\n",
    "                temp_frame,\n",
    "                val,\n",
    "                (10, 100),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "        cv2.putText(\n",
    "            temp_frame,\n",
    "            f\"Traffic light: {traffic_light}\",\n",
    "            (10, 70),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            calcColor(),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        # Show the frame with overlays\n",
    "        cv2.imshow('RGB Camera', temp_frame)\n",
    "        #cv2.imshow('RGB Camera2', video_output2.copy())\n",
    "\n",
    "        # Break the loop on 'q' key press\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Handle Pygame events periodically\n",
    "        current_time = pygame.time.get_ticks()\n",
    "        if current_time - event_timer > EVENT_RATE:\n",
    "            event_timer = current_time\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    break\n",
    "                elif event.type == pygame.KEYUP:  # Handle key releases\n",
    "                    if event.key == pygame.K_e:  # Toggle speed control\n",
    "                        speed_control_activate = not speed_control_activate\n",
    "                    if event.key == pygame.K_c:  # Enable autopilot\n",
    "                        vehicle.set_autopilot(True)\n",
    "                    if event.key == pygame.K_v:  # Disable autopilot\n",
    "                        vehicle.set_autopilot(False)\n",
    "                    if event.key == pygame.K_o:  # Toggle red light detection\n",
    "                        red_over_activate = not red_over_activate\n",
    "\n",
    "            keys = pygame.key.get_pressed()  # Get pressed keys\n",
    "\n",
    "            # Handle speed control logic\n",
    "            if speed_control_activate and last_speed_limit and keys[pygame.K_w]:\n",
    "                # Calculate speed error relative to the limit\n",
    "                error = float(last_speed_limit) - float(speed_car) + 3\n",
    "                if error < -DEAD_ZONE:\n",
    "                    throttle = 0\n",
    "                    brake = max(KP_BRAKE * abs(error), MIN_BRAKE)\n",
    "                else:\n",
    "                    throttle = max(KP_THROTTLE * error, MIN_THROTTLE)\n",
    "                    brake = 0\n",
    "            elif keys[pygame.K_w]:  # Manual throttle control\n",
    "                throttle = min(throttle + throttle_increment, 1)\n",
    "                brake = 0\n",
    "            else:\n",
    "                throttle = 0\n",
    "                brake = 0\n",
    "            \n",
    "            if keys[pygame.K_s]:  # Manual brake control\n",
    "                brake = min(brake + throttle_increment * 4, 1)\n",
    "                throttle = 0\n",
    "\n",
    "            if red_over and int(speed_car) <= 40 and gear != \"Reverse\" and red_over_activate:\n",
    "                brake = 1\n",
    "                throttle = 0\n",
    "\n",
    "            # Handle steering controls\n",
    "            if keys[pygame.K_r]:  # Reverse gear\n",
    "                gear = \"Reverse\"\n",
    "                red_over = False\n",
    "            elif keys[pygame.K_f]:  # Forward gear\n",
    "                gear = \"Drive\"\n",
    "            elif keys[pygame.K_a]:  # Steer left\n",
    "                steer = max(steer - steer_increment, -1)\n",
    "            elif keys[pygame.K_d]:  # Steer right\n",
    "                steer = min(steer + steer_increment, 1)\n",
    "            else:\n",
    "                steer = steer * 0.9  # Gradually return to center\n",
    "\n",
    "            # Apply vehicle controls\n",
    "            control = carla.VehicleControl()\n",
    "            control.throttle = throttle\n",
    "            control.brake = brake\n",
    "            control.steer = steer\n",
    "            control.reverse = (gear == \"Reverse\")\n",
    "            vehicle.apply_control(control)\n",
    "\n",
    "        clock.tick(40)  # Maintain a 40 FPS loop rate\n",
    "finally:\n",
    "    # Clean up resources and connections\n",
    "    cv2.destroyAllWindows()\n",
    "    pygame.quit()\n",
    "    camera.destroy()\n",
    "    camera_trafficLight.destroy()\n",
    "    camera_trafficLight_red_detector.destroy()\n",
    "    camera_view.destroy()\n",
    "    vehicle.destroy()\n",
    "    clientMQTT.disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
